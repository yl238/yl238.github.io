<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Statistics on Sue's Blog</title><link>https://yl238.github.io/tags/statistics/</link><description>Recent content in Statistics on Sue's Blog</description><generator>Hugo -- 0.147.1</generator><language>en-us</language><lastBuildDate>Sat, 03 May 2025 14:29:53 +0100</lastBuildDate><atom:link href="https://yl238.github.io/tags/statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA</title><link>https://yl238.github.io/posts/exp-smoothing-arima/</link><pubDate>Sat, 03 May 2025 14:29:53 +0100</pubDate><guid>https://yl238.github.io/posts/exp-smoothing-arima/</guid><description>&lt;p>Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements.&lt;/p></description><content:encoded><![CDATA[<p>Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements.</p>
<figure>
	<img src="/posts/exp-smoothing-arima/UK-retail-sales-index.png" style="display:block; margin:auto; width:90%"/>
	<figcaption>Figure 1: Retail Sales Index for electrical household appliances. Source:<a href="https://www.ons.gov.uk/businessindustryandtrade/retailindustry/timeseries/jo5f/drsi"> Statistica </a>
	</figcaption>
</figure>
<p>The field of forecasting has advanced rapidly in recent years, with Machine Learning and Deep Learning models increasingly used to tackle time series problems. Nevertheless, traditional methods like <a href="https://otexts.com/fpp3/expsmooth.html">exponential smoothing</a> and <a href="https://otexts.com/fpp3/arima.html">ARIMA</a> remain essential tools for practitioners. They are easy to implement, deliver strong baseline performance, and in many cases, provide results that are competitive with far more complex models (Hyndman 2021). While most modern libraries support these techniques, the underlying details and rationale for using them are often relegated to undergraduate textbooks. In this article, We’ll revisit exponential smoothing and ARIMA, unpack their core ideas, discuss when they are the right choice to use in solving forecasting problems, and share practical tips to help you get started with time series modelling.</p>
<h2 id="exponential-smoothing">Exponential Smoothing</h2>
<p>Exponential smoothing was first introduced in the classic papers by Holt (1957) and Winters (1960), and has since inspired some of the most successful forecasting methods. Put simply, forecasts generated through exponential smoothing are weighted averages of past observations, with the weights decreasing exponentially as the observations become older. In other words, more recent observations are given greater weight than those further in the past.</p>
<h3 id="simple-exponential-smoothing">Simple Exponential Smoothing </h3>
<p>For a time series with observations at times $t=1,\ldots,T$, the simplest forecasting method is to predict that the value at the next time step $T+1$ will be equal to the value at the current time step $T$. This is known as the ‘naïve’ or ‘random walk’ method. The next simplest approach is averaging, where the forecasted value is the average of all previous observations. However, in most cases, we prefer something in between these two extremes, that is, more recent observations are given greater importance, with weights that gradually decrease for older data points. This idea is illustrated in Figure 2, where the rate of weight decay is governed by the parameter $\alpha$.</p>
<figure>
	<img src="/posts/exp-smoothing-arima/expon-decay-weights.png" style="display:block; margin:auto;width:60%"/>
	<figcaption>Figure 2: Exponential decay of weights with older data
	</figcaption>
</figure>
In simple exponential smoothing, the forecast for time $T+1$ is a weighted average of all previous observations from times $1,\ldots,T$, with the weights decreasing exponentially as observations get older. Mathematically, this can be expressed as:
$$
\hat{y}_{T+1|T} = \alpha y_T + \alpha(1-\alpha)y_{T-1} +\alpha(1-\alpha)^2 y_{T-2} + \ldots
$$<p>This model is well-suited for forecasting data with no clear trend or seasonal pattern.</p>
<h3 id="exponential-smoothing-with-trend-and-seasonality">Exponential Smoothing with trend and seasonality</h3>
<p>In practice, most real-world time series exhibit trends, seasonal cycles, or both. For example, Figure 3 shows the monthly employment figures in the hospitality industry from 2000 to 2020 in the US, decomposed into trend and seasonal components. We can observe a clear upward trend in employment over time, along with a regular annual seasonal pattern corresponding to fluctuations across different months of the year.</p>
<figure>
	<img src="/posts/exp-smoothing-arima/seasonal-decomposition.png" style="display:block; margin:auto;width:80%"/>
	<figcaption>Figure 3: Monthly employment figure in hospitality industry in the US from 2000–2020.
	</figcaption>
</figure>
<p>To handle such patterns, we can extend the basic exponential smoothing framework to explicitly model both trend and seasonality. As illustrated in Figure 4, these extended equations allow us to directly model the underlying structure of the employment time series without the need for manual preprocessing, such as detrending or deseasonalising the data beforehand. This makes forecasting more straightforward while capturing the essential dynamics of the series.</p>
<figure>
	<img src="/posts/exp-smoothing-arima/expon-smoothing.png" style="width:100%"/>
	<figcaption>Figure 4. Left: Exponential smoothing equations incorporating trend and seasonality components. Right: Directly fitting the employment time series using the extended model.
	</figcaption>
</figure>
<h2 id="arima">ARIMA</h2>
<p>A second major family of statistical forecasting methods is ARIMA, which stands for <strong>A</strong>uto<strong>R</strong>egressive <strong>I</strong>ntegrated <strong>M</strong>oving <strong>A</strong>verage. ARIMA models combine three techniques: autoregression, differencing (integration), and moving average, to produce accurate forecasts by working with stationary time series data.
The term “autoregressive” reflects the idea that forecasting is treated as a regression problem, where past values of the time series are used as predictors for future values. “Integrated” refers to the process of differencing the data, where consecutive observations are subtracted to remove trends or seasonality and achieve stationarity. After forecasts are generated, the differencing is reversed, or ‘integrated’, to bring the predictions back to the original scale. “Moving average” refers to modelling future values as a linear combination of past forecast errors, capturing short-term dependencies that can improve predictive accuracy.<br>
Table 1 summarises the three main components of the ARIMA model along with brief descriptions of their roles in modelling time series data.</p>
<figure>
	<img src="/posts/exp-smoothing-arima/ARIMA-components.png" style="width:100%"/>
	<figcaption>Table 1: Description of ARIMA components
	</figcaption>
</figure>
<p>Figure 5 illustrates how an ARIMA model is built for an example time series of US Imports from 1960–2007. The original time series $y(t)$ shows a clear upward trend, which means we need to first apply <em>differencing</em> to remove the trend and create a more stable series, $y'(t)$. After this, we build a linear model using the last $p$ values and the $q$ past forecast errors of the differenced time series $y'(t)$ to predict the next value.</p>
<figure>
	<img src="/posts/exp-smoothing-arima/ARIMA-example.png" style="display:block; margin:auto;width:70%"/>
	<figcaption>Figure 5: A step-by-step look at how an ARIMA model is built for a time series.
	</figcaption>
</figure>
<h3 id="seasonal-arima">Seasonal ARIMA</h3>
<p>The basic ARIMA model, as described above, does not account for seasonality in time series data. However, it can be extended to handle seasonal cycles by incorporating additional seasonal terms. The modelling procedure remains largely similar to that for non-seasonal data, with the key difference being that we must now select both seasonal and non-seasonal autoregressive and moving average terms. This extension, often referred to as Seasonal ARIMA (or SARIMA), greatly enhances the model’s ability to capture complex patterns in time series that exhibit regular, repeating seasonal behaviour.</p>
<h2 id="a-comparison-of-exponential-smoothing-andarima">A Comparison of Exponential Smoothing and ARIMA</h2>
<p>Exponential smoothing and ARIMA represent two distinct approaches to time series forecasting, each with its own strengths and limitations. As described earlier, ARIMA models focus on capturing patterns in the autocorrelations of the data by modelling the relationships between the current value, its lagged values, and past forecast errors. In contrast, exponential smoothing methods directly model the level, trend, and seasonal components of a time series. This makes exponential smoothing relatively easy to use and interpret, and particularly robust in scenarios with strong, stable seasonality.</p>
<p>However, because exponential smoothing emphasises smoothing over recent observations, it may not respond well to short-term fluctuations, such as sudden spikes in sales following a promotional event. Such short-term impacts are better captured by the autoregressive and moving average components of an ARIMA model. On the other hand, ARIMA models require the time series to be stationary or made stationary through differencing. The added complexity of tuning autoregressive, differencing, and moving average terms can make them more difficult to build and interpret compared to exponential smoothing.</p>
<figure>
  <img src="/posts/exp-smoothing-arima/ARIMA-expon-smoothing-comparisons.png" style="display:block; margin:auto; width:60%"/>
  <figcaption>Figure 6: Summary of the similarities and differences between ARIMA and Exponential Smoothing (ETS) models.</figcaption>
</figure>
<h2 id="which-model-should-weuse">Which model should we use?</h2>
<figure>
	<img src="/posts/exp-smoothing-arima/ARIMA-expon-smoothing-comparisons-2.png" style="width:100%"/>
	<figcaption>Table 2: Scenarios where Exponential Smoothing or ARIMA models are most appropriate, with real-world examples.
	</figcaption>
</figure>
<p>The choice between Exponential Smoothing and ARIMA models largely depends on the specific forecasting problem at hand. Table 2 provides a summary of when each method is preferred, along with the reasons for these choices. In brief, Exponential Smoothing is most effective when seasonality or trends are strong, stable, and clearly defined, or when a quick, interpretable baseline forecast is needed. In contrast, ARIMA models are better suited to situations where seasonality is weak or irregular, short-term shocks and autocorrelations dominate the data, and greater model sophistication is required to capture complex, irregular fluctuations.</p>
<h2 id="summary">Summary</h2>
<p>I hope this overview has helped you gain a clearer understanding of the principles behind Exponential Smoothing and ARIMA, two of the most widely used approaches in traditional time series forecasting. There are many libraries that implement these models, including <a href="https://www.rdocumentation.org/packages/forecast/versions/8.23.0">Forecast</a> (R), <a href="https://www.statsmodels.org/stable/index.html">Statsmodels</a> (Python) and newer libraries such as <a href="https://www.nixtla.io/">Nixtla</a>, which also offer implementations of machine learning–based forecasting methods. We will explore these more advanced approaches in future posts.</p>
<h2 id="references">References</h2>
<ul>
<li>Hyndman, R.J., &amp; Athanasopoulos, G. (2021) <em>Forecasting: principles and practice</em>, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3.</li>
<li>Gardner, E. S. (1985). Exponential smoothing: The state of the art. <em>Journal of Forecasting</em>, <em>4</em>(1), 1–28. <a href="https://doi.org/10.1002/for.3980040103">[DOI]</a></li>
<li>Box, G. E. P., &amp; Jenkins, G. M. (1970). <em>Time series analysis: Forecasting and control</em>. Holden-Day.</li>
<li>Hyndman, R. J., Koehler, A. B., Ord, J. K., &amp; Snyder, R. D. (2008). <em>Forecasting with exponential smoothing: The state space approach</em>. Springer-Verlag.</li>
</ul>
]]></content:encoded></item></channel></rss>