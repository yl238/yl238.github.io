<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA | Sue's Blog</title>
<meta name=keywords content="Time Series Forecasting,Statistics"><meta name=description content="Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements."><meta name=author content="Sue Liu"><link rel=canonical href=https://yl238.github.io/posts/exp-smoothing-arima/><link crossorigin=anonymous href=/assets/css/stylesheet.5b6fe9bc5862b2c8d2f42962454f59d98958bcb887aa82c1ad7e5f4ee9ee97dd.css integrity="sha256-W2/pvFhissjS9CliRU9Z2YlYvLiHqoLBrX5fTunul90=" rel="preload stylesheet" as=style><link rel=icon href=https://yl238.github.io/images/favicon_puffin.ico><link rel=icon type=image/png sizes=16x16 href=https://yl238.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yl238.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://yl238.github.io/apple-touch-icon.png><link rel=mask-icon href=https://yl238.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://yl238.github.io/posts/exp-smoothing-arima/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://yl238.github.io/posts/exp-smoothing-arima/"><meta property="og:site_name" content="Sue's Blog"><meta property="og:title" content="Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA"><meta property="og:description" content="Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-03T14:29:53+01:00"><meta property="article:modified_time" content="2025-05-03T14:29:53+01:00"><meta property="article:tag" content="Time Series Forecasting"><meta property="article:tag" content="Statistics"><meta name=twitter:card content="summary"><meta name=twitter:title content="Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA"><meta name=twitter:description content="Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yl238.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA","item":"https://yl238.github.io/posts/exp-smoothing-arima/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA","name":"Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA","description":"Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements.\n","keywords":["Time Series Forecasting","Statistics"],"articleBody":"Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements.\nFigure 1: Retail Sales Index for electrical household appliances. Source: Statistica The field of forecasting has advanced rapidly in recent years, with Machine Learning and Deep Learning models increasingly used to tackle time series problems. Nevertheless, traditional methods like exponential smoothing and ARIMA remain essential tools for practitioners. They are easy to implement, deliver strong baseline performance, and in many cases, provide results that are competitive with far more complex models (Hyndman 2021). While most modern libraries support these techniques, the underlying details and rationale for using them are often relegated to undergraduate textbooks. In this article, We’ll revisit exponential smoothing and ARIMA, unpack their core ideas, discuss when they are the right choice to use in solving forecasting problems, and share practical tips to help you get started with time series modelling.\nExponential Smoothing Exponential smoothing was first introduced in the classic papers by Holt (1957) and Winters (1960), and has since inspired some of the most successful forecasting methods. Put simply, forecasts generated through exponential smoothing are weighted averages of past observations, with the weights decreasing exponentially as the observations become older. In other words, more recent observations are given greater weight than those further in the past.\nSimple Exponential Smoothing For a time series with observations at times $t=1,\\ldots,T$, the simplest forecasting method is to predict that the value at the next time step $T+1$ will be equal to the value at the current time step $T$. This is known as the ‘naïve’ or ‘random walk’ method. The next simplest approach is averaging, where the forecasted value is the average of all previous observations. However, in most cases, we prefer something in between these two extremes, that is, more recent observations are given greater importance, with weights that gradually decrease for older data points. This idea is illustrated in Figure 2, where the rate of weight decay is governed by the parameter $\\alpha$.\nFigure 2: Exponential decay of weights with older data In simple exponential smoothing, the forecast for time $T+1$ is a weighted average of all previous observations from times $1,\\ldots,T$, with the weights decreasing exponentially as observations get older. Mathematically, this can be expressed as: $$ \\hat{y}_{T+1|T} = \\alpha y_T + \\alpha(1-\\alpha)y_{T-1} +\\alpha(1-\\alpha)^2 y_{T-2} + \\ldots $$This model is well-suited for forecasting data with no clear trend or seasonal pattern.\nExponential Smoothing with trend and seasonality In practice, most real-world time series exhibit trends, seasonal cycles, or both. For example, Figure 3 shows the monthly employment figures in the hospitality industry from 2000 to 2020 in the US, decomposed into trend and seasonal components. We can observe a clear upward trend in employment over time, along with a regular annual seasonal pattern corresponding to fluctuations across different months of the year.\nFigure 3: Monthly employment figure in hospitality industry in the US from 2000–2020. To handle such patterns, we can extend the basic exponential smoothing framework to explicitly model both trend and seasonality. As illustrated in Figure 4, these extended equations allow us to directly model the underlying structure of the employment time series without the need for manual preprocessing, such as detrending or deseasonalising the data beforehand. This makes forecasting more straightforward while capturing the essential dynamics of the series.\nFigure 4. Left: Exponential smoothing equations incorporating trend and seasonality components. Right: Directly fitting the employment time series using the extended model. ARIMA A second major family of statistical forecasting methods is ARIMA, which stands for AutoRegressive Integrated Moving Average. ARIMA models combine three techniques: autoregression, differencing (integration), and moving average, to produce accurate forecasts by working with stationary time series data. The term “autoregressive” reflects the idea that forecasting is treated as a regression problem, where past values of the time series are used as predictors for future values. “Integrated” refers to the process of differencing the data, where consecutive observations are subtracted to remove trends or seasonality and achieve stationarity. After forecasts are generated, the differencing is reversed, or ‘integrated’, to bring the predictions back to the original scale. “Moving average” refers to modelling future values as a linear combination of past forecast errors, capturing short-term dependencies that can improve predictive accuracy.\nTable 1 summarises the three main components of the ARIMA model along with brief descriptions of their roles in modelling time series data.\nTable 1: Description of ARIMA components Figure 5 illustrates how an ARIMA model is built for an example time series of US Imports from 1960–2007. The original time series $y(t)$ shows a clear upward trend, which means we need to first apply differencing to remove the trend and create a more stable series, $y'(t)$. After this, we build a linear model using the last $p$ values and the $q$ past forecast errors of the differenced time series $y'(t)$ to predict the next value.\nFigure 5: A step-by-step look at how an ARIMA model is built for a time series. Seasonal ARIMA The basic ARIMA model, as described above, does not account for seasonality in time series data. However, it can be extended to handle seasonal cycles by incorporating additional seasonal terms. The modelling procedure remains largely similar to that for non-seasonal data, with the key difference being that we must now select both seasonal and non-seasonal autoregressive and moving average terms. This extension, often referred to as Seasonal ARIMA (or SARIMA), greatly enhances the model’s ability to capture complex patterns in time series that exhibit regular, repeating seasonal behaviour.\nA Comparison of Exponential Smoothing and ARIMA Exponential smoothing and ARIMA represent two distinct approaches to time series forecasting, each with its own strengths and limitations. As described earlier, ARIMA models focus on capturing patterns in the autocorrelations of the data by modelling the relationships between the current value, its lagged values, and past forecast errors. In contrast, exponential smoothing methods directly model the level, trend, and seasonal components of a time series. This makes exponential smoothing relatively easy to use and interpret, and particularly robust in scenarios with strong, stable seasonality.\nHowever, because exponential smoothing emphasises smoothing over recent observations, it may not respond well to short-term fluctuations, such as sudden spikes in sales following a promotional event. Such short-term impacts are better captured by the autoregressive and moving average components of an ARIMA model. On the other hand, ARIMA models require the time series to be stationary or made stationary through differencing. The added complexity of tuning autoregressive, differencing, and moving average terms can make them more difficult to build and interpret compared to exponential smoothing.\nFigure 6: Summary of the similarities and differences between ARIMA and Exponential Smoothing (ETS) models. Which model should we use? Table 2: Scenarios where Exponential Smoothing or ARIMA models are most appropriate, with real-world examples. The choice between Exponential Smoothing and ARIMA models largely depends on the specific forecasting problem at hand. Table 2 provides a summary of when each method is preferred, along with the reasons for these choices. In brief, Exponential Smoothing is most effective when seasonality or trends are strong, stable, and clearly defined, or when a quick, interpretable baseline forecast is needed. In contrast, ARIMA models are better suited to situations where seasonality is weak or irregular, short-term shocks and autocorrelations dominate the data, and greater model sophistication is required to capture complex, irregular fluctuations.\nSummary I hope this overview has helped you gain a clearer understanding of the principles behind Exponential Smoothing and ARIMA, two of the most widely used approaches in traditional time series forecasting. There are many libraries that implement these models, including Forecast (R), Statsmodels (Python) and newer libraries such as Nixtla, which also offer implementations of machine learning–based forecasting methods. We will explore these more advanced approaches in future posts.\nReferences Hyndman, R.J., \u0026 Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Gardner, E. S. (1985). Exponential smoothing: The state of the art. Journal of Forecasting, 4(1), 1–28. [DOI] Box, G. E. P., \u0026 Jenkins, G. M. (1970). Time series analysis: Forecasting and control. Holden-Day. Hyndman, R. J., Koehler, A. B., Ord, J. K., \u0026 Snyder, R. D. (2008). Forecasting with exponential smoothing: The state space approach. Springer-Verlag. ","wordCount":"1444","inLanguage":"en","datePublished":"2025-05-03T14:29:53+01:00","dateModified":"2025-05-03T14:29:53+01:00","author":{"@type":"Person","name":"Sue Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yl238.github.io/posts/exp-smoothing-arima/"},"publisher":{"@type":"Organization","name":"Sue's Blog","logo":{"@type":"ImageObject","url":"https://yl238.github.io/images/favicon_puffin.ico"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]},loader:{load:["ui/safe"]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yl238.github.io/ accesskey=h title="Sue's Blog (Alt + H)">Sue's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yl238.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://yl238.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yl238.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://yl238.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://yl238.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Time Series Forecasting Methods (Part 1): Exponential Smoothing and ARIMA</h1><div class=post-meta><span title='2025-05-03 14:29:53 +0100 +0100'>May 3, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Sue Liu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#exponential-smoothing aria-label="Exponential Smoothing">Exponential Smoothing</a><ul><li><a href=#simple-exponential-smoothing aria-label="Simple Exponential Smoothing ">Simple Exponential Smoothing </a></li><li><a href=#exponential-smoothing-with-trend-and-seasonality aria-label="Exponential Smoothing with trend and seasonality">Exponential Smoothing with trend and seasonality</a></li></ul></li><li><a href=#arima aria-label=ARIMA>ARIMA</a><ul><li><a href=#seasonal-arima aria-label="Seasonal ARIMA">Seasonal ARIMA</a></li></ul></li><li><a href=#a-comparison-of-exponential-smoothing-andarima aria-label="A Comparison of Exponential Smoothing and ARIMA">A Comparison of Exponential Smoothing and ARIMA</a></li><li><a href=#which-model-should-weuse aria-label="Which model should we use?">Which model should we use?</a></li><li><a href=#summary aria-label=Summary>Summary</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p>Time series forecasting refers to the use of historical data to predict future values, and enabling the identification of patterns and trends that inform decision-making. An example time series is the UK Retail Sales Index for electrical household appliances from 1988 to 2025 (Figure 1), which provides seasonally adjusted retail sales in Great Britain in both value and volume terms. The ability to accurately forecast such data is crucial, as it helps business stakeholders and policymakers make well-informed decisions in scenarios such as setting economic policies, managing inventory or planning staffing requirements.</p><figure><img src=/posts/exp-smoothing-arima/UK-retail-sales-index.png style=display:block;margin:auto;width:90%><figcaption>Figure 1: Retail Sales Index for electrical household appliances. Source:<a href=https://www.ons.gov.uk/businessindustryandtrade/retailindustry/timeseries/jo5f/drsi> Statistica</a></figcaption></figure><p>The field of forecasting has advanced rapidly in recent years, with Machine Learning and Deep Learning models increasingly used to tackle time series problems. Nevertheless, traditional methods like <a href=https://otexts.com/fpp3/expsmooth.html>exponential smoothing</a> and <a href=https://otexts.com/fpp3/arima.html>ARIMA</a> remain essential tools for practitioners. They are easy to implement, deliver strong baseline performance, and in many cases, provide results that are competitive with far more complex models (Hyndman 2021). While most modern libraries support these techniques, the underlying details and rationale for using them are often relegated to undergraduate textbooks. In this article, We’ll revisit exponential smoothing and ARIMA, unpack their core ideas, discuss when they are the right choice to use in solving forecasting problems, and share practical tips to help you get started with time series modelling.</p><h2 id=exponential-smoothing>Exponential Smoothing<a hidden class=anchor aria-hidden=true href=#exponential-smoothing>#</a></h2><p>Exponential smoothing was first introduced in the classic papers by Holt (1957) and Winters (1960), and has since inspired some of the most successful forecasting methods. Put simply, forecasts generated through exponential smoothing are weighted averages of past observations, with the weights decreasing exponentially as the observations become older. In other words, more recent observations are given greater weight than those further in the past.</p><h3 id=simple-exponential-smoothing>Simple Exponential Smoothing <a hidden class=anchor aria-hidden=true href=#simple-exponential-smoothing>#</a></h3><p>For a time series with observations at times $t=1,\ldots,T$, the simplest forecasting method is to predict that the value at the next time step $T+1$ will be equal to the value at the current time step $T$. This is known as the ‘naïve’ or ‘random walk’ method. The next simplest approach is averaging, where the forecasted value is the average of all previous observations. However, in most cases, we prefer something in between these two extremes, that is, more recent observations are given greater importance, with weights that gradually decrease for older data points. This idea is illustrated in Figure 2, where the rate of weight decay is governed by the parameter $\alpha$.</p><figure><img src=/posts/exp-smoothing-arima/expon-decay-weights.png style=display:block;margin:auto;width:60%><figcaption>Figure 2: Exponential decay of weights with older data</figcaption></figure>In simple exponential smoothing, the forecast for time $T+1$ is a weighted average of all previous observations from times $1,\ldots,T$, with the weights decreasing exponentially as observations get older. Mathematically, this can be expressed as:
$$
\hat{y}_{T+1|T} = \alpha y_T + \alpha(1-\alpha)y_{T-1} +\alpha(1-\alpha)^2 y_{T-2} + \ldots
$$<p>This model is well-suited for forecasting data with no clear trend or seasonal pattern.</p><h3 id=exponential-smoothing-with-trend-and-seasonality>Exponential Smoothing with trend and seasonality<a hidden class=anchor aria-hidden=true href=#exponential-smoothing-with-trend-and-seasonality>#</a></h3><p>In practice, most real-world time series exhibit trends, seasonal cycles, or both. For example, Figure 3 shows the monthly employment figures in the hospitality industry from 2000 to 2020 in the US, decomposed into trend and seasonal components. We can observe a clear upward trend in employment over time, along with a regular annual seasonal pattern corresponding to fluctuations across different months of the year.</p><figure><img src=/posts/exp-smoothing-arima/seasonal-decomposition.png style=display:block;margin:auto;width:80%><figcaption>Figure 3: Monthly employment figure in hospitality industry in the US from 2000–2020.</figcaption></figure><p>To handle such patterns, we can extend the basic exponential smoothing framework to explicitly model both trend and seasonality. As illustrated in Figure 4, these extended equations allow us to directly model the underlying structure of the employment time series without the need for manual preprocessing, such as detrending or deseasonalising the data beforehand. This makes forecasting more straightforward while capturing the essential dynamics of the series.</p><figure><img src=/posts/exp-smoothing-arima/expon-smoothing.png style=width:100%><figcaption>Figure 4. Left: Exponential smoothing equations incorporating trend and seasonality components. Right: Directly fitting the employment time series using the extended model.</figcaption></figure><h2 id=arima>ARIMA<a hidden class=anchor aria-hidden=true href=#arima>#</a></h2><p>A second major family of statistical forecasting methods is ARIMA, which stands for <strong>A</strong>uto<strong>R</strong>egressive <strong>I</strong>ntegrated <strong>M</strong>oving <strong>A</strong>verage. ARIMA models combine three techniques: autoregression, differencing (integration), and moving average, to produce accurate forecasts by working with stationary time series data.
The term “autoregressive” reflects the idea that forecasting is treated as a regression problem, where past values of the time series are used as predictors for future values. “Integrated” refers to the process of differencing the data, where consecutive observations are subtracted to remove trends or seasonality and achieve stationarity. After forecasts are generated, the differencing is reversed, or ‘integrated’, to bring the predictions back to the original scale. “Moving average” refers to modelling future values as a linear combination of past forecast errors, capturing short-term dependencies that can improve predictive accuracy.<br>Table 1 summarises the three main components of the ARIMA model along with brief descriptions of their roles in modelling time series data.</p><figure><img src=/posts/exp-smoothing-arima/ARIMA-components.png style=width:100%><figcaption>Table 1: Description of ARIMA components</figcaption></figure><p>Figure 5 illustrates how an ARIMA model is built for an example time series of US Imports from 1960–2007. The original time series $y(t)$ shows a clear upward trend, which means we need to first apply <em>differencing</em> to remove the trend and create a more stable series, $y'(t)$. After this, we build a linear model using the last $p$ values and the $q$ past forecast errors of the differenced time series $y'(t)$ to predict the next value.</p><figure><img src=/posts/exp-smoothing-arima/ARIMA-example.png style=display:block;margin:auto;width:70%><figcaption>Figure 5: A step-by-step look at how an ARIMA model is built for a time series.</figcaption></figure><h3 id=seasonal-arima>Seasonal ARIMA<a hidden class=anchor aria-hidden=true href=#seasonal-arima>#</a></h3><p>The basic ARIMA model, as described above, does not account for seasonality in time series data. However, it can be extended to handle seasonal cycles by incorporating additional seasonal terms. The modelling procedure remains largely similar to that for non-seasonal data, with the key difference being that we must now select both seasonal and non-seasonal autoregressive and moving average terms. This extension, often referred to as Seasonal ARIMA (or SARIMA), greatly enhances the model’s ability to capture complex patterns in time series that exhibit regular, repeating seasonal behaviour.</p><h2 id=a-comparison-of-exponential-smoothing-andarima>A Comparison of Exponential Smoothing and ARIMA<a hidden class=anchor aria-hidden=true href=#a-comparison-of-exponential-smoothing-andarima>#</a></h2><p>Exponential smoothing and ARIMA represent two distinct approaches to time series forecasting, each with its own strengths and limitations. As described earlier, ARIMA models focus on capturing patterns in the autocorrelations of the data by modelling the relationships between the current value, its lagged values, and past forecast errors. In contrast, exponential smoothing methods directly model the level, trend, and seasonal components of a time series. This makes exponential smoothing relatively easy to use and interpret, and particularly robust in scenarios with strong, stable seasonality.</p><p>However, because exponential smoothing emphasises smoothing over recent observations, it may not respond well to short-term fluctuations, such as sudden spikes in sales following a promotional event. Such short-term impacts are better captured by the autoregressive and moving average components of an ARIMA model. On the other hand, ARIMA models require the time series to be stationary or made stationary through differencing. The added complexity of tuning autoregressive, differencing, and moving average terms can make them more difficult to build and interpret compared to exponential smoothing.</p><figure><img src=/posts/exp-smoothing-arima/ARIMA-expon-smoothing-comparisons.png style=display:block;margin:auto;width:60%><figcaption>Figure 6: Summary of the similarities and differences between ARIMA and Exponential Smoothing (ETS) models.</figcaption></figure><h2 id=which-model-should-weuse>Which model should we use?<a hidden class=anchor aria-hidden=true href=#which-model-should-weuse>#</a></h2><figure><img src=/posts/exp-smoothing-arima/ARIMA-expon-smoothing-comparisons-2.png style=width:100%><figcaption>Table 2: Scenarios where Exponential Smoothing or ARIMA models are most appropriate, with real-world examples.</figcaption></figure><p>The choice between Exponential Smoothing and ARIMA models largely depends on the specific forecasting problem at hand. Table 2 provides a summary of when each method is preferred, along with the reasons for these choices. In brief, Exponential Smoothing is most effective when seasonality or trends are strong, stable, and clearly defined, or when a quick, interpretable baseline forecast is needed. In contrast, ARIMA models are better suited to situations where seasonality is weak or irregular, short-term shocks and autocorrelations dominate the data, and greater model sophistication is required to capture complex, irregular fluctuations.</p><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>I hope this overview has helped you gain a clearer understanding of the principles behind Exponential Smoothing and ARIMA, two of the most widely used approaches in traditional time series forecasting. There are many libraries that implement these models, including <a href=https://www.rdocumentation.org/packages/forecast/versions/8.23.0>Forecast</a> (R), <a href=https://www.statsmodels.org/stable/index.html>Statsmodels</a> (Python) and newer libraries such as <a href=https://www.nixtla.io/>Nixtla</a>, which also offer implementations of machine learning–based forecasting methods. We will explore these more advanced approaches in future posts.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ul><li>Hyndman, R.J., & Athanasopoulos, G. (2021) <em>Forecasting: principles and practice</em>, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3.</li><li>Gardner, E. S. (1985). Exponential smoothing: The state of the art. <em>Journal of Forecasting</em>, <em>4</em>(1), 1–28. <a href=https://doi.org/10.1002/for.3980040103>[DOI]</a></li><li>Box, G. E. P., & Jenkins, G. M. (1970). <em>Time series analysis: Forecasting and control</em>. Holden-Day.</li><li>Hyndman, R. J., Koehler, A. B., Ord, J. K., & Snyder, R. D. (2008). <em>Forecasting with exponential smoothing: The state space approach</em>. Springer-Verlag.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://yl238.github.io/tags/time-series-forecasting/>Time Series Forecasting</a></li><li><a href=https://yl238.github.io/tags/statistics/>Statistics</a></li></ul><nav class=paginav><a class=prev href=https://yl238.github.io/posts/hugo-papermod-gh/><span class=title>« Prev</span><br><span>Create a Static Blog with Hugo, PaperMod and Github Pages</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://yl238.github.io/>Sue's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>