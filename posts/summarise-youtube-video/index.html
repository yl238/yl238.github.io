<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Using LLMs to Evaluate Youtube Videos | Sue's Blog</title>
<meta name=keywords content="LLMs,life-hacks"><meta name=description content="I often get recommended YouTube videos with catchy titles but not much substance. To save time, I built a simple app that downloads the transcript of the video, feeds it to ChatGPT, and generates a quick summary, key moments, and any fresh insights the video offers. After skimming this I can decide if the video is worth watching. It’s been a huge time-saver, so I’m sharing the code here, along with a quick overview of how it works."><meta name=author content="Sue Liu"><link rel=canonical href=https://yl238.github.io/posts/summarise-youtube-video/><link crossorigin=anonymous href=/assets/css/stylesheet.16f8f12cd8c6dd8a08cc3b01540747086edf66df441677072a74a6ef8134e29d.css integrity="sha256-FvjxLNjG3YoIzDsBVAdHCG7fZt9EFncHKnSm74E04p0=" rel="preload stylesheet" as=style><link rel=icon href=https://yl238.github.io/images/favicon_puffin.ico><link rel=icon type=image/png sizes=16x16 href=https://yl238.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yl238.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://yl238.github.io/apple-touch-icon.png><link rel=mask-icon href=https://yl238.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://yl238.github.io/posts/summarise-youtube-video/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://yl238.github.io/posts/summarise-youtube-video/"><meta property="og:site_name" content="Sue's Blog"><meta property="og:title" content="Using LLMs to Evaluate Youtube Videos"><meta property="og:description" content="I often get recommended YouTube videos with catchy titles but not much substance. To save time, I built a simple app that downloads the transcript of the video, feeds it to ChatGPT, and generates a quick summary, key moments, and any fresh insights the video offers. After skimming this I can decide if the video is worth watching. It’s been a huge time-saver, so I’m sharing the code here, along with a quick overview of how it works."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-04T10:50:10+01:00"><meta property="article:modified_time" content="2025-05-04T10:50:10+01:00"><meta property="article:tag" content="LLMs"><meta property="article:tag" content="Life-Hacks"><meta name=twitter:card content="summary"><meta name=twitter:title content="Using LLMs to Evaluate Youtube Videos"><meta name=twitter:description content="I often get recommended YouTube videos with catchy titles but not much substance. To save time, I built a simple app that downloads the transcript of the video, feeds it to ChatGPT, and generates a quick summary, key moments, and any fresh insights the video offers. After skimming this I can decide if the video is worth watching. It’s been a huge time-saver, so I’m sharing the code here, along with a quick overview of how it works."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yl238.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Using LLMs to Evaluate Youtube Videos","item":"https://yl238.github.io/posts/summarise-youtube-video/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Using LLMs to Evaluate Youtube Videos","name":"Using LLMs to Evaluate Youtube Videos","description":"I often get recommended YouTube videos with catchy titles but not much substance. To save time, I built a simple app that downloads the transcript of the video, feeds it to ChatGPT, and generates a quick summary, key moments, and any fresh insights the video offers. After skimming this I can decide if the video is worth watching. It’s been a huge time-saver, so I’m sharing the code here, along with a quick overview of how it works.\n","keywords":["LLMs","life-hacks"],"articleBody":"I often get recommended YouTube videos with catchy titles but not much substance. To save time, I built a simple app that downloads the transcript of the video, feeds it to ChatGPT, and generates a quick summary, key moments, and any fresh insights the video offers. After skimming this I can decide if the video is worth watching. It’s been a huge time-saver, so I’m sharing the code here, along with a quick overview of how it works.\nHere is path to the repo.\nExample usage Before running the code, be sure to install the required packages. Also, create a .env file (or set environment variables) for:\nWHISPER_PATH- the local OpenAI Whisper installation path, for optional local transcription OPENAI_API_KEY- your OpenAI API key pip install -r requirements.txt streamlit run streamlit_app.py This will open the Streamlit app on a web browser, where you can paste the URL of the Youtube video you want to evaluate. The response will be displayed on the page. Using GPT-4o you summarisation videos with lengths up to an hour.\nIf you don’t want to spend money on the API, you can run the script youtube_evaluator.py in a terminal. When you are asked whether you want to only create the prompt, type 'y'. This will simply download the transcript and create a file called prompt.txt, which contains the prompt along with the full text of the transcript. You can the copy/paste the text into the web console of ChatGPT, Gemini or Grok and see the response there. This is the way if you want to use a provider other than OpenAI.\nWe use as an example a video which attempts to explain Transformers in 6 minutes.\nRun in the terminal:\npython youtube_evaluator.py Enter a YouTube video URL: https://www.youtube.com/watch?v=ZXiruGOCn9s Only create LLM prompt? (y/n): y This will generate the prompt.txt file. The response returned from ChatGPT informs me that this is actually an overview of GPT-3, so I’m not watching it! Now I’ve saved myself 6 minutes.\nHow it works Transcript Acquisition:\nThe YouTubeVideoEvaluator first tries to retrieve a transcript via the YouTube Transcript API. If it can’t find one (or an error occurs), it downloads the video (preferring an audio-only stream) using pytube and passes the downloaded file to AudioTranscriber to generate a transcript.\nTranscription: (Optional)\nThe AudioTranscriber uses ffmpeg to convert the input file to WAV and then calls the Whisper CLI to perform the transcription. (The inplace flag is set to False when processing a downloaded file so the original isn’t overwritten.) Note this is only called when the transcription is not available, and requires you to set up OpenAI’s Whisper model locally. I use the C++ port for MacOS\nLLM Processing:\nThe generated (or API-provided) transcript is passed to the LLMProcessor, which sends it to OpenAI’s ChatCompletion endpoint. The prompt instructs the LLM to summarise and extract the main points with timestamps. You can swap this for another LLM or update the prompt text as needed.\nOutput:\nThe final summary is shown in the Streamlit app or printed to the console.\nFinally, I’m happy to hear any suggestions for improvements or new ideas on how to use LLMs!\n","wordCount":"524","inLanguage":"en","datePublished":"2025-05-04T10:50:10+01:00","dateModified":"2025-05-04T10:50:10+01:00","author":{"@type":"Person","name":"Sue Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yl238.github.io/posts/summarise-youtube-video/"},"publisher":{"@type":"Organization","name":"Sue's Blog","logo":{"@type":"ImageObject","url":"https://yl238.github.io/images/favicon_puffin.ico"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]},loader:{load:["ui/safe"]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yl238.github.io/ accesskey=h title="Sue's Blog (Alt + H)">Sue's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yl238.github.io/about/ title=About><span>About</span></a></li><li><a href=https://yl238.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://yl238.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yl238.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Using LLMs to Evaluate Youtube Videos</h1><div class=post-meta><span title='2025-05-04 10:50:10 +0100 +0100'>May 4, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Sue Liu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#example-usage aria-label="Example usage">Example usage</a></li><li><a href=#how-it-works aria-label="How it works">How it works</a></li></ul></div></details></div><div class=post-content><p>I often get recommended YouTube videos with catchy titles but not much substance. To save time, I built a simple app that downloads the transcript of the video, feeds it to ChatGPT, and generates a quick summary, key moments, and any fresh insights the video offers. After skimming this I can decide if the video is worth watching. It’s been a huge time-saver, so I’m sharing the code here, along with a quick overview of how it works.</p><p>Here is <a href=https://github.com/yl238/llm-personal-assistant>path to the repo</a>.</p><h2 id=example-usage>Example usage<a hidden class=anchor aria-hidden=true href=#example-usage>#</a></h2><p>Before running the code, be sure to install the required packages. Also, create a <code>.env</code> file (or set environment variables) for:</p><ul><li><code>WHISPER_PATH</code>- the local OpenAI Whisper installation path, for optional local transcription</li><li><code>OPENAI_API_KEY</code>- your OpenAI API key</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install -r requirements.txt
</span></span><span style=display:flex><span>streamlit run streamlit_app.py
</span></span></code></pre></div><p>This will open the Streamlit app on a web browser, where you can paste the URL of the Youtube video you want to evaluate. The response will be displayed on the page. Using GPT-4o you summarisation videos with lengths up to an hour.</p><img src=/posts/summarise-youtube-video/streamlit-app.png width=90%><p>If you don&rsquo;t want to spend money on the API, you can run the script <a href=https://github.com/yl238/llm-personal-assistant/blob/main/youtube_evaluator.py>youtube_evaluator.py</a> in a terminal. When you are asked whether you want to only create the prompt, type <code>'y'</code>. This will simply download the transcript and create a file called <code>prompt.txt</code>, which contains the prompt along with the full text of the transcript. You can the copy/paste the text into the web console of ChatGPT, Gemini or Grok and see the response there. This is the way if you want to use a provider other than OpenAI.</p><p>We use as an example a video which attempts to <a href="https://www.youtube.com/watch?v=ZXiruGOCn9s">explain Transformers in 6 minutes</a>.</p><p>Run in the terminal:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python youtube_evaluator.py
</span></span></code></pre></div><pre tabindex=0><code>Enter a YouTube video URL: https://www.youtube.com/watch?v=ZXiruGOCn9s
Only create LLM prompt? (y/n): y
</code></pre><p>This will generate the <code>prompt.txt</code> file. The response returned from ChatGPT informs me that this is actually an overview of GPT-3, so I&rsquo;m not watching it! Now I&rsquo;ve saved myself 6 minutes.</p><h2 id=how-it-works>How it works<a hidden class=anchor aria-hidden=true href=#how-it-works>#</a></h2><ol><li><p><strong>Transcript Acquisition:</strong><br>The <code>YouTubeVideoEvaluator</code> first tries to retrieve a transcript via the <a href=https://pypi.org/project/youtube-transcript-api/>YouTube Transcript API</a>. If it can’t find one (or an error occurs), it downloads the video (preferring an audio-only stream) using <a href=https://pytube.io/>pytube</a> and passes the downloaded file to <code>AudioTranscriber</code> to generate a transcript.</p></li><li><p><strong>Transcription: (Optional)</strong><br>The <code>AudioTranscriber</code> uses ffmpeg to convert the input file to WAV and then calls the Whisper CLI to perform the transcription. (The <code>inplace</code> flag is set to <code>False</code> when processing a downloaded file so the original isn’t overwritten.) Note this is only called when the transcription is not available, and requires you to set up OpenAI&rsquo;s Whisper model locally. I use the <a href=https://github.com/ggml-org/whisper.cpp>C++ port for MacOS</a></p></li><li><p><strong>LLM Processing:</strong><br>The generated (or API-provided) transcript is passed to the <code>LLMProcessor</code>, which sends it to OpenAI’s ChatCompletion endpoint. The prompt instructs the LLM to summarise and extract the main points with timestamps. You can swap this for another LLM or update the prompt text as needed.</p></li><li><p><strong>Output:</strong><br>The final summary is shown in the Streamlit app or printed to the console.</p></li></ol><p>Finally, I&rsquo;m happy to hear any suggestions for improvements or new ideas on how to use LLMs!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://yl238.github.io/tags/llms/>LLMs</a></li><li><a href=https://yl238.github.io/tags/life-hacks/>Life-Hacks</a></li></ul><nav class=paginav><a class=prev href=https://yl238.github.io/posts/using-obsidian/><span class=title>« Prev</span><br><span>How I use Obsidian</span>
</a><a class=next href=https://yl238.github.io/posts/hugo-papermod-gh/><span class=title>Next »</span><br><span>Create a Static Blog with Hugo, PaperMod and Github Pages</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://yl238.github.io/>Sue's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>